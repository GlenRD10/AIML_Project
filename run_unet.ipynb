{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "run_unet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9VOpOQ1q3tg"
      },
      "source": [
        "import pathlib\n",
        "import sys\n",
        "from collections import defaultdict\n",
        "import h5py\n",
        "import numpy as np\n",
        "import torch\n",
        "import logging\n",
        "import shutil\n",
        "import time\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5Ix2hH4sN2_"
      },
      "source": [
        "args = {\n",
        "    'seed': 42,\n",
        "    'resolution': 320,\n",
        "    'challenge': 'singlecoil',\n",
        "    'data_path': pathlib.Path('/content/drive/MyDrive/Dataset'),\n",
        "    'sample_rate': 1.,\n",
        "    'accelerations': [4, 8],\n",
        "    'center_fractions': [0.08, 0.04],\n",
        "\n",
        "    'mask_kspace': False,\n",
        "    'data_split': 'test',\n",
        "    'checkpoint': pathlib.Path('/content/drive/MyDrive/checkpoints/best_model.pt'),\n",
        "    'out_dir': pathlib.Path('/content/drive/MyDrive/reconstructions'),\n",
        "    'batch_size': 16,\n",
        "    'device': 'cuda'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzf8_rfHsCD_"
      },
      "source": [
        "def save_reconstructions(reconstructions, out_dir):\n",
        "    out_dir.mkdir(exist_ok=True)\n",
        "    for fname, recons in reconstructions.items():\n",
        "        with h5py.File(out_dir / fname, 'w') as f:\n",
        "            f.create_dataset('reconstruction', data=recons)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGnh7wfMsOpV"
      },
      "source": [
        "class MaskFunc:\n",
        "\n",
        "  def __init__(self, center_fractions, accelerations):\n",
        "    if len(center_fractions) != len(accelerations):\n",
        "        raise ValueError('Number of center fractions should match number of accelerations')\n",
        "\n",
        "    self.center_fractions = center_fractions\n",
        "    self.accelerations = accelerations\n",
        "    self.rng = np.random.RandomState()\n",
        "\n",
        "  def __call__(self, shape, seed=None):\n",
        "    if len(shape) < 3:\n",
        "        raise ValueError('Shape should have 3 or more dimensions')\n",
        "\n",
        "    self.rng.seed(seed)\n",
        "    num_cols = shape[-2]\n",
        "\n",
        "    choice = self.rng.randint(0, len(self.accelerations))\n",
        "    center_fraction = self.center_fractions[choice]\n",
        "    acceleration = self.accelerations[choice]\n",
        "\n",
        "    # Create the mask\n",
        "    num_low_freqs = int(round(num_cols * center_fraction))\n",
        "    prob = (num_cols / acceleration - num_low_freqs) / (num_cols - num_low_freqs)\n",
        "    mask = self.rng.uniform(size=num_cols) < prob\n",
        "    pad = (num_cols - num_low_freqs + 1) // 2\n",
        "    mask[pad:pad + num_low_freqs] = True\n",
        "\n",
        "    # Reshape the mask\n",
        "    mask_shape = [1 for _ in shape]\n",
        "    mask_shape[-2] = num_cols\n",
        "    mask = torch.from_numpy(mask.reshape(*mask_shape).astype(np.float32))\n",
        "\n",
        "    return mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6De3zWHssZ23"
      },
      "source": [
        "def to_tensor(data):\n",
        "  if np.iscomplexobj(data):\n",
        "      data = np.stack((data.real, data.imag), axis=-1)\n",
        "  return torch.from_numpy(data)\n",
        "\n",
        "\n",
        "def apply_mask(data, mask_func, seed=None):\n",
        "  shape = np.array(data.shape)\n",
        "  shape[:-3] = 1\n",
        "  mask = mask_func(shape, seed)\n",
        "  return torch.where(mask == 0, torch.Tensor([0]), data), mask\n",
        "\n",
        "\n",
        "def fft2(data):\n",
        "  assert data.size(-1) == 2\n",
        "  data = ifftshift(data, dim=(-3, -2))\n",
        "  data = torch.fft.fft(data, dim=2, norm='backward')\n",
        "  data = fftshift(data, dim=(-3, -2))\n",
        "  return data\n",
        "\n",
        "\n",
        "def ifft2(data):\n",
        "  assert data.size(-1) == 2\n",
        "  data = ifftshift(data, dim=(-3, -2))\n",
        "  data = torch.fft.ifft(data, dim=2, norm='backward')\n",
        "  data = fftshift(data, dim=(-3, -2))\n",
        "  return data\n",
        "\n",
        "\n",
        "def complex_abs(data):\n",
        "  assert data.size(-1) == 2\n",
        "  return (data ** 2).sum(dim=-1).sqrt()\n",
        "\n",
        "\n",
        "def root_sum_of_squares(data, dim=0):\n",
        "  return torch.sqrt((data ** 2).sum(dim))\n",
        "\n",
        "\n",
        "def center_crop(data, shape):\n",
        "  assert 0 < shape[0] <= data.shape[-2]\n",
        "  assert 0 < shape[1] <= data.shape[-1]\n",
        "  w_from = (data.shape[-2] - shape[0]) // 2\n",
        "  h_from = (data.shape[-1] - shape[1]) // 2\n",
        "  w_to = w_from + shape[0]\n",
        "  h_to = h_from + shape[1]\n",
        "  return data[..., w_from:w_to, h_from:h_to]\n",
        "\n",
        "\n",
        "def complex_center_crop(data, shape):\n",
        "  assert 0 < shape[0] <= data.shape[-3]\n",
        "  assert 0 < shape[1] <= data.shape[-2]\n",
        "  w_from = (data.shape[-3] - shape[0]) // 2\n",
        "  h_from = (data.shape[-2] - shape[1]) // 2\n",
        "  w_to = w_from + shape[0]\n",
        "  h_to = h_from + shape[1]\n",
        "  return data[..., w_from:w_to, h_from:h_to, :]\n",
        "\n",
        "\n",
        "def normalize(data, mean, stddev, eps=0.):\n",
        "  return (data - mean) / (stddev + eps)\n",
        "\n",
        "\n",
        "def normalize_instance(data, eps=0.):\n",
        "  mean = data.mean()\n",
        "  std = data.std()\n",
        "  return normalize(data, mean, std, eps), mean, std\n",
        "\n",
        "\n",
        "# Helper functions\n",
        "\n",
        "def roll(x, shift, dim):\n",
        "  if isinstance(shift, (tuple, list)):\n",
        "      assert len(shift) == len(dim)\n",
        "      for s, d in zip(shift, dim):\n",
        "          x = roll(x, s, d)\n",
        "      return x\n",
        "  shift = shift % x.size(dim)\n",
        "  if shift == 0:\n",
        "      return x\n",
        "  left = x.narrow(dim, 0, x.size(dim) - shift)\n",
        "  right = x.narrow(dim, x.size(dim) - shift, shift)\n",
        "  return torch.cat((right, left), dim=dim)\n",
        "\n",
        "\n",
        "def fftshift(x, dim=None):\n",
        "  if dim is None:\n",
        "      dim = tuple(range(x.dim()))\n",
        "      shift = [dim // 2 for dim in x.shape]\n",
        "  elif isinstance(dim, int):\n",
        "      shift = x.shape[dim] // 2\n",
        "  else:\n",
        "      shift = [x.shape[i] // 2 for i in dim]\n",
        "  return roll(x, shift, dim)\n",
        "\n",
        "\n",
        "def ifftshift(x, dim=None):\n",
        "  if dim is None:\n",
        "      dim = tuple(range(x.dim()))\n",
        "      shift = [(dim + 1) // 2 for dim in x.shape]\n",
        "  elif isinstance(dim, int):\n",
        "      shift = (x.shape[dim] + 1) // 2\n",
        "  else:\n",
        "      shift = [(x.shape[i] + 1) // 2 for i in dim]\n",
        "  return roll(x, shift, dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sXb_JoGseQG"
      },
      "source": [
        "class SliceData(Dataset):\n",
        "\n",
        "  def __init__(self, root, transform, challenge, sample_rate=1):\n",
        "    if challenge not in ('singlecoil', 'multicoil'):\n",
        "        raise ValueError('challenge should be either \"singlecoil\" or \"multicoil\"')\n",
        "\n",
        "    self.transform = transform\n",
        "    self.recons_key = 'reconstruction_esc' if challenge == 'singlecoil' \\\n",
        "        else 'reconstruction_rss'\n",
        "\n",
        "    self.examples = []\n",
        "    files = list(pathlib.Path(root).iterdir())\n",
        "    if sample_rate < 1:\n",
        "        random.shuffle(files)\n",
        "        num_files = round(len(files) * sample_rate)\n",
        "        files = files[:num_files]\n",
        "    for fname in sorted(files):\n",
        "        kspace = h5py.File(fname, 'r')['kspace']\n",
        "        num_slices = kspace.shape[0]\n",
        "        self.examples += [(fname, slice) for slice in range(num_slices)]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.examples)\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    fname, slice = self.examples[i]\n",
        "    with h5py.File(fname, 'r') as data:\n",
        "        kspace = data['kspace'][slice]\n",
        "        target = data[self.recons_key][slice] if self.recons_key in data else None\n",
        "        return self.transform(kspace, target, data.attrs, fname.name, slice)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCOFcxsPsi98"
      },
      "source": [
        "class ConvBlock(nn.Module):\n",
        "\n",
        "  def __init__(self, in_chans, out_chans, drop_prob):\n",
        "      super().__init__()\n",
        "\n",
        "      self.in_chans = in_chans\n",
        "      self.out_chans = out_chans\n",
        "      self.drop_prob = drop_prob\n",
        "\n",
        "      self.layers = nn.Sequential(\n",
        "          nn.Conv2d(in_chans, out_chans, kernel_size=3, padding=1),\n",
        "          nn.InstanceNorm2d(out_chans),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout2d(drop_prob),\n",
        "          nn.Conv2d(out_chans, out_chans, kernel_size=3, padding=1),\n",
        "          nn.InstanceNorm2d(out_chans),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout2d(drop_prob)\n",
        "      )\n",
        "\n",
        "  def forward(self, input):\n",
        "      return self.layers(input)\n",
        "\n",
        "  def __repr__(self):\n",
        "      return f'ConvBlock(in_chans={self.in_chans}, out_chans={self.out_chans}, ' \\\n",
        "          f'drop_prob={self.drop_prob})'\n",
        "\n",
        "\n",
        "class UnetModel(nn.Module):\n",
        "\n",
        "  def __init__(self, in_chans, out_chans, chans, num_pool_layers, drop_prob):\n",
        "      super().__init__()\n",
        "\n",
        "      self.in_chans = in_chans\n",
        "      self.out_chans = out_chans\n",
        "      self.chans = chans\n",
        "      self.num_pool_layers = num_pool_layers\n",
        "      self.drop_prob = drop_prob\n",
        "\n",
        "      self.down_sample_layers = nn.ModuleList([ConvBlock(in_chans, chans, drop_prob)])\n",
        "      ch = chans\n",
        "      for i in range(num_pool_layers - 1):\n",
        "          self.down_sample_layers += [ConvBlock(ch, ch * 2, drop_prob)]\n",
        "          ch *= 2\n",
        "      self.conv = ConvBlock(ch, ch, drop_prob)\n",
        "\n",
        "      self.up_sample_layers = nn.ModuleList()\n",
        "      for i in range(num_pool_layers - 1):\n",
        "          self.up_sample_layers += [ConvBlock(ch * 2, ch // 2, drop_prob)]\n",
        "          ch //= 2\n",
        "      self.up_sample_layers += [ConvBlock(ch * 2, ch, drop_prob)]\n",
        "      self.conv2 = nn.Sequential(\n",
        "          nn.Conv2d(ch, ch // 2, kernel_size=1),\n",
        "          nn.Conv2d(ch // 2, out_chans, kernel_size=1),\n",
        "          nn.Conv2d(out_chans, out_chans, kernel_size=1),\n",
        "      )\n",
        "\n",
        "  def forward(self, input):\n",
        "      stack = []\n",
        "      output = input\n",
        "      # Apply down-sampling layers\n",
        "      for layer in self.down_sample_layers:\n",
        "          output = layer(output)\n",
        "          stack.append(output)\n",
        "          output = F.max_pool2d(output, kernel_size=2)\n",
        "\n",
        "      output = self.conv(output)\n",
        "\n",
        "      # Apply up-sampling layers\n",
        "      for layer in self.up_sample_layers:\n",
        "          output = F.interpolate(output, scale_factor=2, mode='bilinear', align_corners=False)\n",
        "          output = torch.cat([output, stack.pop()], dim=1)\n",
        "          output = layer(output)\n",
        "      return self.conv2(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dQWVG0Bs7nX"
      },
      "source": [
        "class DataTransform:\n",
        "\n",
        "    def __init__(self, resolution, which_challenge, mask_func=None):\n",
        "        if which_challenge not in ('singlecoil', 'multicoil'):\n",
        "            raise ValueError(f'Challenge should either be \"singlecoil\" or \"multicoil\"')\n",
        "        self.resolution = resolution\n",
        "        self.which_challenge = which_challenge\n",
        "        self.mask_func = mask_func\n",
        "\n",
        "    def __call__(self, kspace, target, attrs, fname, slice):\n",
        "        kspace = to_tensor(kspace)\n",
        "        if self.mask_func is not None:\n",
        "            seed = tuple(map(ord, fname))\n",
        "            masked_kspace, _ = apply_mask(kspace, self.mask_func, seed)\n",
        "        else:\n",
        "            masked_kspace = kspace\n",
        "        # Inverse Fourier Transform to get zero filled solution\n",
        "        image = ifft2(masked_kspace)\n",
        "        # Crop input image\n",
        "        image = complex_center_crop(image, (self.resolution, self.resolution))\n",
        "        # Absolute value\n",
        "        image = image.abs()\n",
        "        # Apply Root-Sum-of-Squares if multicoil data\n",
        "        if self.which_challenge == 'multicoil':\n",
        "            image = root_sum_of_squares(image)\n",
        "        # Normalize input\n",
        "        image, mean, std = normalize_instance(image)\n",
        "        image = image.clamp(-6, 6)\n",
        "        return image, mean, std, fname, slice"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tVYnvphuvSC"
      },
      "source": [
        "def create_data_loaders(args):\n",
        "  mask_func = None\n",
        "  if args['mask_kspace']:\n",
        "      mask_func = MaskFunc(args['center_fractions'], args['accelerations'])\n",
        "  challenge=args['challenge']\n",
        "  data_split=args['data_split']\n",
        "  data = SliceData(\n",
        "      root=args['data_path'] / f'{challenge}_{data_split}',\n",
        "      transform=DataTransform(args['resolution'], args['challenge'], mask_func),\n",
        "      sample_rate=1.,\n",
        "      challenge=args['challenge']\n",
        "  )\n",
        "  data_loader = DataLoader(\n",
        "      dataset=data,\n",
        "      batch_size=args['batch_size'],\n",
        "      num_workers=4,\n",
        "      pin_memory=True,\n",
        "  )\n",
        "  return data_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pwdls36QxOjr"
      },
      "source": [
        "def load_model(checkpoint_file):\n",
        "  checkpoint = torch.load(checkpoint_file)\n",
        "  args = checkpoint['args']\n",
        "  model = UnetModel(1, 1, args['num_chans'], args['num_pools'], args['drop_prob']).to(args['device'])\n",
        "  if args['data_parallel']:\n",
        "      model = torch.nn.DataParallel(model)\n",
        "  model.load_state_dict(checkpoint['model'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEHixYkQxaOB"
      },
      "source": [
        "def run_unet(args, model, data_loader):\n",
        "  model.eval()\n",
        "  reconstructions = defaultdict(list)\n",
        "  with torch.no_grad():\n",
        "      for (input, mean, std, fnames, slices) in data_loader:\n",
        "          input = input.unsqueeze(1).to(args['device'])\n",
        "          input_new = (input[:, :, :, :, 0] + input[:, :, :, :, 1]) / 2\n",
        "          recons = model(input_new).to('cpu').squeeze(1)\n",
        "          for i in range(recons.shape[0]):\n",
        "              recons[i] = recons[i] * std[i] + mean[i]\n",
        "              reconstructions[fnames[i]].append((slices[i].numpy(), recons[i].numpy()))\n",
        "\n",
        "  reconstructions = {\n",
        "      fname: np.stack([pred for _, pred in sorted(slice_preds)])\n",
        "      for fname, slice_preds in reconstructions.items()\n",
        "  }\n",
        "  return reconstructions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uq1EfM8Ixotb",
        "outputId": "4deb7693-ce61-4001-91ca-b3ede4e4187e"
      },
      "source": [
        "data_loader = create_data_loaders(args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hOZAX9XxqWx"
      },
      "source": [
        "model = load_model(args['checkpoint'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-Rv5_XmxsVy",
        "outputId": "dfec09bc-275c-4497-fbcf-07a4432bcb17"
      },
      "source": [
        "reconstructions = run_unet(args, model, data_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zUv4u_yxucJ"
      },
      "source": [
        "save_reconstructions(reconstructions, args['out_dir'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}